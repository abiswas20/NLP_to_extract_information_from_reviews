{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 10, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.get_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.set_threshold(100,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"./data/Books.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5\n",
      "Name: overall, dtype: int64\n",
      "1000000    5\n",
      "Name: overall, dtype: int64\n",
      "2000000    2\n",
      "Name: overall, dtype: int64\n",
      "3000000    3\n",
      "Name: overall, dtype: int64\n",
      "4000000    5\n",
      "Name: overall, dtype: int64\n",
      "5000000    5\n",
      "Name: overall, dtype: int64\n",
      "6000000    1\n",
      "Name: overall, dtype: int64\n",
      "7000000    5\n",
      "Name: overall, dtype: int64\n",
      "8000000    4\n",
      "Name: overall, dtype: int64\n",
      "9000000    5\n",
      "Name: overall, dtype: int64\n",
      "10000000    5\n",
      "Name: overall, dtype: int64\n",
      "11000000    5\n",
      "Name: overall, dtype: int64\n",
      "12000000    5\n",
      "Name: overall, dtype: int64\n",
      "13000000    5\n",
      "Name: overall, dtype: int64\n",
      "14000000    5\n",
      "Name: overall, dtype: int64\n",
      "15000000    5\n",
      "Name: overall, dtype: int64\n",
      "16000000    5\n",
      "Name: overall, dtype: int64\n",
      "17000000    5\n",
      "Name: overall, dtype: int64\n",
      "18000000    4\n",
      "Name: overall, dtype: int64\n",
      "19000000    4\n",
      "Name: overall, dtype: int64\n",
      "20000000    2\n",
      "Name: overall, dtype: int64\n",
      "21000000    5\n",
      "Name: overall, dtype: int64\n",
      "22000000    5\n",
      "Name: overall, dtype: int64\n",
      "23000000    3\n",
      "Name: overall, dtype: int64\n",
      "24000000    5\n",
      "Name: overall, dtype: int64\n",
      "25000000    4\n",
      "Name: overall, dtype: int64\n",
      "26000000    5\n",
      "Name: overall, dtype: int64\n",
      "27000000    5\n",
      "Name: overall, dtype: int64\n",
      "28000000    4\n",
      "Name: overall, dtype: int64\n",
      "29000000    5\n",
      "Name: overall, dtype: int64\n",
      "30000000    5\n",
      "Name: overall, dtype: int64\n",
      "31000000    5\n",
      "Name: overall, dtype: int64\n",
      "32000000    5\n",
      "Name: overall, dtype: int64\n",
      "33000000    5\n",
      "Name: overall, dtype: int64\n",
      "34000000    3\n",
      "Name: overall, dtype: int64\n",
      "35000000    5\n",
      "Name: overall, dtype: int64\n",
      "36000000    5\n",
      "Name: overall, dtype: int64\n",
      "37000000    5\n",
      "Name: overall, dtype: int64\n",
      "38000000    3\n",
      "Name: overall, dtype: int64\n",
      "39000000    5\n",
      "Name: overall, dtype: int64\n",
      "40000000    5\n",
      "Name: overall, dtype: int64\n",
      "41000000    2\n",
      "Name: overall, dtype: int64\n",
      "42000000    5\n",
      "Name: overall, dtype: int64\n",
      "43000000    5\n",
      "Name: overall, dtype: int64\n",
      "44000000    5\n",
      "Name: overall, dtype: int64\n",
      "45000000    5\n",
      "Name: overall, dtype: int64\n",
      "46000000    5\n",
      "Name: overall, dtype: int64\n",
      "47000000    3\n",
      "Name: overall, dtype: int64\n",
      "48000000    5\n",
      "Name: overall, dtype: int64\n",
      "49000000    4\n",
      "Name: overall, dtype: int64\n",
      "50000000    5\n",
      "Name: overall, dtype: int64\n",
      "51000000    5\n",
      "Name: overall, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Let's scan the csv to see how dates are ordered\n",
    "#dx=pd.DataFrame()\n",
    "chunksize=10**6\n",
    "for chunk in pd.read_json(filename, lines=True,orient='columns',chunksize=chunksize,nrows=100_000_000):\n",
    "    dx=pd.DataFrame(chunk)\n",
    "    dx=dx['overall'] #,'verified','reviewText','unixReviewTime']\n",
    "    print(dx.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are over 51 million reviews in this dataset. Let's take a sample distributed throughout the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 9, 78)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.get_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk # 1\n",
      "Processing chunk # 2\n",
      "Processing chunk # 3\n",
      "Processing chunk # 4\n",
      "Processing chunk # 5\n",
      "Processing chunk # 6\n",
      "Processing chunk # 7\n",
      "Processing chunk # 8\n",
      "Processing chunk # 9\n",
      "Processing chunk # 10\n",
      "Processing chunk # 11\n",
      "Processing chunk # 12\n",
      "Processing chunk # 13\n",
      "Processing chunk # 14\n",
      "Processing chunk # 15\n",
      "Processing chunk # 16\n",
      "Processing chunk # 17\n",
      "Processing chunk # 18\n",
      "Processing chunk # 19\n",
      "Processing chunk # 20\n",
      "Processing chunk # 21\n",
      "Processing chunk # 22\n",
      "Processing chunk # 23\n",
      "Processing chunk # 24\n",
      "Processing chunk # 25\n",
      "Processing chunk # 26\n",
      "Processing chunk # 27\n",
      "Processing chunk # 28\n",
      "Processing chunk # 29\n",
      "Processing chunk # 30\n",
      "Processing chunk # 31\n",
      "Processing chunk # 32\n",
      "Processing chunk # 33\n",
      "Processing chunk # 34\n",
      "Processing chunk # 35\n",
      "Processing chunk # 36\n",
      "Processing chunk # 37\n",
      "Processing chunk # 38\n",
      "Processing chunk # 39\n",
      "Processing chunk # 40\n",
      "Processing chunk # 41\n",
      "Processing chunk # 42\n",
      "Processing chunk # 43\n",
      "Processing chunk # 44\n",
      "Processing chunk # 45\n",
      "Processing chunk # 46\n",
      "Processing chunk # 47\n",
      "Processing chunk # 48\n",
      "Processing chunk # 49\n",
      "Processing chunk # 50\n",
      "Processing chunk # 51\n",
      "Processing chunk # 52\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.set_threshold(200,5,5)\n",
    "j=0\n",
    "selected_data=pd.DataFrame()\n",
    "chunksize=1_000_000\n",
    "for chunk in pd.read_json(filename, lines=True,chunksize=chunksize,nrows=100_000_000):\n",
    "    selected_data=pd.DataFrame()\n",
    "    dx=pd.DataFrame()\n",
    "    print('Processing chunk #',j+1)\n",
    "    dx=pd.DataFrame(chunk)\n",
    "    dx_sample=dx.sample(frac=0.25)[['asin','overall','verified','reviewText','unixReviewTime']]\n",
    "    selected_data=pd.concat([selected_data,dx_sample])\n",
    "    output_file='./data/Amazon_book_reviews-Sample'+str(j+1)+'.csv'\n",
    "    selected_data.to_csv(output_file,index=0)\n",
    "    del dx_sample\n",
    "    del selected_data\n",
    "    gc.collect()\n",
    "    j+=1\n",
    "    if j>51:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files=[('./data/Amazon_book_reviews-Sample'+str(i+1)+'.csv') for i in range(52)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the first 2 lines of each file to see if they are ordered in any way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>file name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007420412</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>I loved this book and can't wait to read book ...</td>\n",
       "      <td>1416355200</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0007444117</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>I was a huge fan when the Divergent series sta...</td>\n",
       "      <td>1472860800</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>006195070X</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>story keeps you entertained throughout the who...</td>\n",
       "      <td>1394496000</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample2.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006058405X</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>I waited for months for this book to be releas...</td>\n",
       "      <td>1324080000</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample2.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0071364102</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>Really enjoyed the insight here.  She covers v...</td>\n",
       "      <td>1394582400</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample3.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1502995948</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>Very fun book about 3 dogs and their owners tr...</td>\n",
       "      <td>1418688000</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample50.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B007YXUQ3C</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>Thanks for the quick delivery and your item wa...</td>\n",
       "      <td>1506556800</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample51.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B007EDDTBI</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>Another in the Serge Series from David Shone, ...</td>\n",
       "      <td>1459209600</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample51.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B015RPT73S</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>When I received notice a second edition of Wri...</td>\n",
       "      <td>1455148800</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample52.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0076644472</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>Book is good and concepts well explained. Howe...</td>\n",
       "      <td>1509667200</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample52.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          asin  overall  verified  \\\n",
       "0   0007420412        5      True   \n",
       "1   0007444117        1     False   \n",
       "0   006195070X        5      True   \n",
       "1   006058405X        4      True   \n",
       "0   0071364102        5      True   \n",
       "..         ...      ...       ...   \n",
       "1   1502995948        5      True   \n",
       "0   B007YXUQ3C        5      True   \n",
       "1   B007EDDTBI        5      True   \n",
       "0   B015RPT73S        5      True   \n",
       "1   0076644472        4      True   \n",
       "\n",
       "                                           reviewText  unixReviewTime  \\\n",
       "0   I loved this book and can't wait to read book ...      1416355200   \n",
       "1   I was a huge fan when the Divergent series sta...      1472860800   \n",
       "0   story keeps you entertained throughout the who...      1394496000   \n",
       "1   I waited for months for this book to be releas...      1324080000   \n",
       "0   Really enjoyed the insight here.  She covers v...      1394582400   \n",
       "..                                                ...             ...   \n",
       "1   Very fun book about 3 dogs and their owners tr...      1418688000   \n",
       "0   Thanks for the quick delivery and your item wa...      1506556800   \n",
       "1   Another in the Serge Series from David Shone, ...      1459209600   \n",
       "0   When I received notice a second edition of Wri...      1455148800   \n",
       "1   Book is good and concepts well explained. Howe...      1509667200   \n",
       "\n",
       "                                  file name  \n",
       "0    ./data/Amazon_book_reviews-Sample1.csv  \n",
       "1    ./data/Amazon_book_reviews-Sample1.csv  \n",
       "0    ./data/Amazon_book_reviews-Sample2.csv  \n",
       "1    ./data/Amazon_book_reviews-Sample2.csv  \n",
       "0    ./data/Amazon_book_reviews-Sample3.csv  \n",
       "..                                      ...  \n",
       "1   ./data/Amazon_book_reviews-Sample50.csv  \n",
       "0   ./data/Amazon_book_reviews-Sample51.csv  \n",
       "1   ./data/Amazon_book_reviews-Sample51.csv  \n",
       "0   ./data/Amazon_book_reviews-Sample52.csv  \n",
       "1   ./data/Amazon_book_reviews-Sample52.csv  \n",
       "\n",
       "[104 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heads=pd.DataFrame()\n",
    "for file in data_files:\n",
    "    file_heads=pd.read_csv(file).head(2)\n",
    "    file_heads['file name']=file\n",
    "    df_heads=pd.concat([df_heads,file_heads])\n",
    "df_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 104 entries, 0 to 1\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   asin            104 non-null    object\n",
      " 1   overall         104 non-null    int64 \n",
      " 2   verified        104 non-null    bool  \n",
      " 3   reviewText      104 non-null    object\n",
      " 4   unixReviewTime  104 non-null    int64 \n",
      " 5   file name       104 non-null    object\n",
      "dtypes: bool(1), int64(2), object(3)\n",
      "memory usage: 5.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_heads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heads['unixReviewTime']=(pd.to_datetime(df_heads['unixReviewTime'],unit='s'))\n",
    "df_heads.rename(columns={'unixReviewTime':'reviewTime'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>file name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007420412</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>I loved this book and can't wait to read book ...</td>\n",
       "      <td>2014-11-19</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0007444117</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>I was a huge fan when the Divergent series sta...</td>\n",
       "      <td>2016-09-03</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>006195070X</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>story keeps you entertained throughout the who...</td>\n",
       "      <td>2014-03-11</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample2.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006058405X</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>I waited for months for this book to be releas...</td>\n",
       "      <td>2011-12-17</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample2.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0071364102</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>Really enjoyed the insight here.  She covers v...</td>\n",
       "      <td>2014-03-12</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample3.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1502995948</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>Very fun book about 3 dogs and their owners tr...</td>\n",
       "      <td>2014-12-16</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample50.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B007YXUQ3C</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>Thanks for the quick delivery and your item wa...</td>\n",
       "      <td>2017-09-28</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample51.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B007EDDTBI</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>Another in the Serge Series from David Shone, ...</td>\n",
       "      <td>2016-03-29</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample51.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B015RPT73S</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>When I received notice a second edition of Wri...</td>\n",
       "      <td>2016-02-11</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample52.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0076644472</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>Book is good and concepts well explained. Howe...</td>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>./data/Amazon_book_reviews-Sample52.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          asin  overall  verified  \\\n",
       "0   0007420412        5      True   \n",
       "1   0007444117        1     False   \n",
       "0   006195070X        5      True   \n",
       "1   006058405X        4      True   \n",
       "0   0071364102        5      True   \n",
       "..         ...      ...       ...   \n",
       "1   1502995948        5      True   \n",
       "0   B007YXUQ3C        5      True   \n",
       "1   B007EDDTBI        5      True   \n",
       "0   B015RPT73S        5      True   \n",
       "1   0076644472        4      True   \n",
       "\n",
       "                                           reviewText reviewTime  \\\n",
       "0   I loved this book and can't wait to read book ... 2014-11-19   \n",
       "1   I was a huge fan when the Divergent series sta... 2016-09-03   \n",
       "0   story keeps you entertained throughout the who... 2014-03-11   \n",
       "1   I waited for months for this book to be releas... 2011-12-17   \n",
       "0   Really enjoyed the insight here.  She covers v... 2014-03-12   \n",
       "..                                                ...        ...   \n",
       "1   Very fun book about 3 dogs and their owners tr... 2014-12-16   \n",
       "0   Thanks for the quick delivery and your item wa... 2017-09-28   \n",
       "1   Another in the Serge Series from David Shone, ... 2016-03-29   \n",
       "0   When I received notice a second edition of Wri... 2016-02-11   \n",
       "1   Book is good and concepts well explained. Howe... 2017-11-03   \n",
       "\n",
       "                                  file name  \n",
       "0    ./data/Amazon_book_reviews-Sample1.csv  \n",
       "1    ./data/Amazon_book_reviews-Sample1.csv  \n",
       "0    ./data/Amazon_book_reviews-Sample2.csv  \n",
       "1    ./data/Amazon_book_reviews-Sample2.csv  \n",
       "0    ./data/Amazon_book_reviews-Sample3.csv  \n",
       "..                                      ...  \n",
       "1   ./data/Amazon_book_reviews-Sample50.csv  \n",
       "0   ./data/Amazon_book_reviews-Sample51.csv  \n",
       "1   ./data/Amazon_book_reviews-Sample51.csv  \n",
       "0   ./data/Amazon_book_reviews-Sample52.csv  \n",
       "1   ./data/Amazon_book_reviews-Sample52.csv  \n",
       "\n",
       "[104 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is not ordered by date. Let's select all reviews after 2015-07-01 from all 52 data files where reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file: ./data/Amazon_book_reviews-Sample1.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample2.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample3.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample4.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample5.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample6.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample7.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample8.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample9.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample10.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample11.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample12.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample13.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample14.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample15.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample16.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample17.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample18.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample19.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample20.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample21.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample22.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample23.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample24.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample25.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample26.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample27.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample28.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample29.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample30.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample31.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample32.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample33.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample34.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample35.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample36.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample37.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample38.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample39.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample40.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample41.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample42.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample43.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample44.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample45.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample46.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample47.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample48.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample49.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample50.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample51.csv\n",
      "processing file: ./data/Amazon_book_reviews-Sample52.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.set_threshold(150,5,5)\n",
    "file_df=pd.DataFrame()\n",
    "for file in data_files:\n",
    "    print('processing file:',file)\n",
    "    df=pd.read_csv(file)\n",
    "    df['unixReviewTime']=(pd.to_datetime(df['unixReviewTime'],unit='s'))\n",
    "    df.rename(columns={'unixReviewTime':'reviewTime'},inplace=True)\n",
    "    df=df[df['reviewTime']>'2015-07-01'].copy(deep=True)\n",
    "    file_df=pd.concat([file_df,df])\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "file_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0007444117</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>I was a huge fan when the Divergent series sta...</td>\n",
       "      <td>2016-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0007177437</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>Excellent read.</td>\n",
       "      <td>2015-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0007327064</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>From the very beginning.. I have loved Odd Tho...</td>\n",
       "      <td>2016-07-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall  verified  \\\n",
       "1  0007444117        1     False   \n",
       "5  0007177437        4      True   \n",
       "6  0007327064        5      True   \n",
       "\n",
       "                                          reviewText reviewTime  \n",
       "1  I was a huge fan when the Divergent series sta... 2016-09-03  \n",
       "5                                    Excellent read. 2015-09-16  \n",
       "6  From the very beginning.. I have loved Odd Tho... 2016-07-17  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's save this dataframe as a csv file\n",
    "file_df.to_csv('./data/pre_processed_data.csv',index=0)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-236d5fca574e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mfile_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file_df' is not defined"
     ]
    }
   ],
   "source": [
    "del file_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
